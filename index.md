---
layout: homepage
---

## About me

It is my pleasure to meet you here. I am **Zhaoji Zhang(张 兆骥 in Simplified Chinese)**, a graduate student from Peking University. After 4-year hard work at Peking University, I earned 2 Bachelor of Science on **Chemical Biology** and  **Intelligence Science and Technology**(also known as AI). I am persuing my Ph.D. in **Integrated Life Science** at [**Center of Life Science(CLS)@PKU-THU (2025-)**](https://www.cls.edu.cn/index.htm). Currently I am still in rotation, and willing to explore different aspects of neuroscience labs.

My curiosity about Neuroscience, especially circuit, computation, and system neuroscience, has led me to be an intern at [Yatang-Li's Lab](https://yatanglilab.cibr.ac.cn/en/) at the Chinese Institute for Brain Research, Beijing (CIBR, Beijing) and finally led me into integrated life science program at Center for Life Science, Academy for Advanced Interdisciplinary Studies, Peking University.

[My resume](https://github.com/Zhang-Zhaoji/Zhang-Zhaoji.github.io/blob/main/assets/files/Resume.pdf) and [my undergraduate_academic transcript](https://drive.google.com/file/d/1somZXkrMlVg3rWUyF3WMa0-Za7p0GWp_/view?usp=sharing) are available for a deeper look into my academic journey, and you can find my research profile on [ORCID](https://orcid.org/0009-0002-3293-1961). 

If you want to contact me, please email me at **2501111571@stu.pku.edu.cn** or **zhang-zj@stu.pku.edu.cn**. Checking my student e-mail is one of my daily routine, so I would respond that in around 24 hours.

## Research Interests

- **Neuroscience:** circuit-system neuroscience, dendritic computing, Saliency Detection & Perception, Visual Encoding&Decoding, BMI/BCI.
  -  Currently I am thinking a novel idea of dendritic logical computing. Following the traditional Rosenblatt's Perceptron computing mechanism(y = f(Σwx+b)), Artificial Neural Networks have created a new era. However, as proposed by [David Beniaguev and Michael London](https://elsc.huji.ac.il/people-directory/faculty-members/michael-london/) in [Single cortical neurons as deep artificial neural networks](https://www.cell.com/neuron/fulltext/S0896-6273(21)00501-8), the neuron is not just a simple point and a non-linear function as the Perceptron assumed. On the countrary, the dendritic computation is relatively way more complex. They used a DNN to mimic neuron, but actually the model might be simplified as few logical gates and a single soma non-linear function. Since the synapses could be modelled as [AND gate, AND NOT gate, and OR gate](https://www.cnbc.cmu.edu/~tai/readings/nature/koch_neuron.pdf), we want to develop a graph-based heuristic searching algorithm (including genetic algorithm), to reconstruct or even design a neuronal dendritic morphological model.
  -  Another more biological idea is to find if we could discover synapse-level position shift or exchange. The position exchanges between OR gates are not that important (and there are almost no results showing that spines would shift a lot), while exchange an OR gate with one AND or AND NOT gate would cause great influence at a relative low cost (and the inhibitory synapse might be more 'flexible' than excitatory synapses at the same time). Figuring out the determination and plasticity mechanisms in real biological systems seems very interesting to me.
  -  I am also looking forward to join a lab which values computation and experiment at the same time, for computation helps us understand the mechanism, and experiment enables us to examine our ideas and always guides our approach.
- **Computer Vision:** Saliency Detection, Video Saliency Detection, segmentation.
  -  A novel approach of computing plausible fixation points from saliency map could be use contour integration on pre-computed saliency maps. We hypothesised that there may exist some 1D-projection-integration circuit, which is observed in [large flocks](https://www.pnas.org/doi/full/10.1073/pnas.1402202111). the contour may be determined by saliency maps and Markovian transition(similar to algorithms in [GBVS, by Harel et al.](https://proceedings.neurips.cc/paper/2006/file/4db0f8b0fc895da263fd77fc8aecabe4-Paper.pdf)).
  - I want to build a giant dataset of dashboard camera recordings of traffic accidents. Although lot of efforts have been put in this fields since 2016 [Anticipating Accidents in Dashcam Videos](https://github.com/smallcorgi/Anticipating-Accidents), we still have the chance to build a dozens-of-thousand-video dataset with fine language labelling at near zero cost, if we use online Danmaku(弹幕) comments as language labels. If you are not familar with Danmaku, you may visit [one video with some Danmaku](https://www.bilibili.com/video/BV1gc4uzZEP6/), and the colored texts floating around are what people referred as Danmaku.
  - Another interesting problem is to train model to do new jobs like segment octopus and do pose estimations (which is quite complex due to its flexibility).
- **Multi Agent Reinforcement Learning:**
  -  Researchers have made a lot of works in MARL, including [AlphaStar](https://deepmind.google/discover/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii/). Although nowadays MARL sometimes is sometimes refered as a technique for building 'Agentic' LLMs, the key findings (to me) are RL algorithms(including natural gradients, GRPO, PPO etc.), self-play, reservior-computing, and insights in game theory.
  -  And it is very cool to discover how herd, octopus, and other multi-body/agent dynamical system behave. How do they perform such complex behaviors through very simple computaion techniques, just like things happening in our brain, the ANNs, and superconductive materials? The studies of natural messaging and learning might give us new insights for designing algorithms of reinforcement learning.
- Recently I have learned some basic electronic skills including Arduino&ESP programming, Soldering, and PCB designation. Maybe I would put them into use in our lab in the future. Molecular Biology (also organic chemistry) experiments are sometimes boring, time consuming, highly repetitive and tedious for many human experimenters. What if we do a little coding here?

## News

- 2025 September: I attended [The 18th Annual Meeting of Chinese Neuroscience Society(CNS) at Xi'an](https://cns.org.cn/2025/). We held a poster at P15-46, and published [our abstract](https://github.com/Zhang-Zhaoji/Zhang-Zhaoji.github.io/blob/main/assets/files/abstractAtCNS2025.pdf) online. However, the full work have not been published yet. We may not send out private data now, but might be available soon. During the conference I met a couple of my old friends and (ex)colleagues, and attend several inspiring sessions, including those held by Songting Li, Kexin Yuan, Xinyu Zhao, Zengcai Guo, Huihui ZHang, Athena Akrami, Qianli Yang, Jiayi Zhang and other researchers. Thank you for your excellent reports and great works. 
- 2025 September: I entered [Prof. Fang Fang's Lab](https://www.psy.pku.edu.cn/szdw/qzjy/jsyjy/ffjs/index.htm) at School of Psychological and Cognitive Sciences, Peking University for the first rotation position, and doing some computational modeling of Rhythmic Attention Sampling.
- 2025 September: I have a great time talking to [Prof. Kexin Yuan](https://brain.tsinghua.edu.cn/info/1010/1015.htm) At Tsinghua University and Yixiao Gao, the PhD student who developed the [VIVIT technique](https://www.cell.com/cell/fulltext/S0092-8674(25)00813-X). We had a lot of fun, wish we could have more collebration in the future.
- 2025 September: I got trained in the 4th Training Course on Neural Modeling and Programming held by [Si Wu Lab](https://www.psy.pku.edu.cn/szdw/qzjy/jsyjy/ws/index.htm) and successfully got the certificate of using [brainpy](https://github.com/brainpy) to model neural dynamics.
- 2025 August: Attend the [first neuro-morphic computing summer camp(第一届类脑计算特训营)](https://gdiist.cn/news/detail/6/375) held by Guangdong Institute of Intelligence Science and Technology (GDIIST) at Hengqin district, Zhuhai city, Guangdong province, China. We talked a lot about the neuro-morphic computing, the Brainpy framework, and advanced neuroscience topics. [Prof. Songting Li](https://ins.sjtu.edu.cn/people/songtingli/) from STJU gave us a talk about dendritic computing and small-world network, which makes me realized that the logic computing on dendrites could be a really complex as well as powerful tools for neuron computing.  I also talked with Dr. Tao Tang and Dr. Yan Chen at GDIIST, they both are very successful researchers and willing to talk to any dedicated students, thus we had a great time.
- 2025 August: Our poster of biological plausible saliency detection is going to be displayed on the CNS 2025 conference at Xi'an, Shaanxi, China in the late September, 2025. 
- 2025 July: I just graduate from Peking Univ at 02/07/2025. Currently I am still continuing research at **CIBR**. Maybe after August I would have more personal time to travel around the world(or just in china). But it turned out that I worked there for around 2 full months, using their 4 ✖ A100 GPUs to do some extra deep-learning works. (eventually I spent the whole summer there, but almost complete the whole project, especially for the traffic accident anticipation part.)
- 2025 April: We have published our research about Saliency Detection in mouse Superior Colliculus(SC) Recently on **Communications Biology** in the name of [Preference-independent saliency map in the mouse superior colliculus](https://www.nature.com/articles/s42003-025-08006-x). I would say it might be a underrated decision because saliency detection is such an important problem and mouse SC may give us a alternative way to think about it, in another way besides triditional Zhaoping's V1 Saliency hypothesis.

